**AI Voice Agent â€“ ELARA AI**

An interactive AI Voice Agent built with FastAPI, AssemblyAI, MurfAI, and OpenAI, capable of real-time conversation using speech-to-text (STT), text-to-speech (TTS), personas, and special skills.


![Python](https://img.shields.io/badge/Python-3.9%2B-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-0.95%2B-green)
![WebSockets](https://img.shields.io/badge/WebSockets-Supported-orange)
![AssemblyAI](https://img.shields.io/badge/AssemblyAI-STT-red)
![Gemini](https://img.shields.io/badge/Gemini-LLM-purple)
![Murf](https://img.shields.io/badge/Murf-TTS-yellow)


**This project was built as part of the 30 Days of AI Voice Agents Challenge. By @MURFAI**


## ğŸ“Œ Project Overview
The **AI Voice Agent ELARAAI** enables real-time **speech-to-speech interaction**.  
It records audio, transcribes it with **AssemblyAI**, processes with **Gemini LLM**,  
and speaks back with **Murf TTS**.  

---


## ğŸš€ Features
- ğŸ¤ **Voice Input** â†’ Records audio in real-time.  
- ğŸ“ **Speech-to-Text (STT)** â†’ AssemblyAI for transcription.  
- ğŸ§  **AI Reasoning** â†’ Gemini LLM handles queries.  
- ğŸ”Š **Text-to-Speech (TTS)** â†’ Murf converts responses.  
- ğŸŒ **Web Search Integration** â†’ Optional external info.  
- ğŸ’¾ **Chat History Storage** â†’ Keeps logs.  
- âš¡ **FastAPI + WebSockets** â†’ Real-time interaction.
 

**ğŸ› ï¸ Tech Stack**

Backend: FastAPI (Python)

Frontend: HTML, CSS, JavaScript (MediaStream API)

APIs:

AssemblyAI (Speech-to-Text)

MurfAI (Text-to-Speech)

OpenAI (LLM for conversations)

Deployment: Render

**Project Structure**
  voice-agent/
â”‚â”€â”€ main.py          # FastAPI backend  
â”‚â”€â”€ static/
â”‚    â”œâ”€â”€ index.html  # Frontend UI  
â”‚    â”œâ”€â”€ script.js   # Handles audio, STT, and TTS  
â”‚    â””â”€â”€ style.css   # UI styling  
â”‚â”€â”€ requirements.txt # Python dependencies  
â”‚â”€â”€ README.md        # Documentation  


**âš¡ Getting Started**

1ï¸âƒ£ Clone the Repository
git clone https://github.com/your-username/voice-agent.git
cd voice-agent

2ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

3ï¸âƒ£ Run the Backend
uvicorn main:app --reload

4ï¸âƒ£ Open the Frontend

Simply open static/index.html in your browser.

**ğŸ”‘ Configuration**

Before using the agent, youâ€™ll need API keys for:

AssemblyAI API â†’ Get key here

MurfAI API â†’ Get key here

OpenAI API â†’ Get key here

â¡ï¸ You can enter these API keys directly in the UI config section.

**ğŸŒ Deployment**

This project is deployed on Render for public access.


**ğŸ”® Future Improvements**

Add multilingual support (Hindi, Spanish, etc.)

Build a memory system so the agent remembers past conversations

Improve UI/UX with better styling and animations

Add more special skills (calendar, reminders, finance updates)

**ğŸ™Œ Acknowledgements**

This project was built as part of the 30 Days of AI Voice Agents Challenge By MURFAI
.
Special thanks to MurfAI, AssemblyAI, and OpenAI for their APIs.

**ğŸ‘©â€ğŸ’» Author**

**Isha Shrivastava**
LinkedIn: https://www.linkedin.com/in/isha-shrivastava0604?utm_source=share&utm_campaign=share_via&utm_content=profile&utm_medium=android_app
